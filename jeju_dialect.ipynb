{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\utility\\Python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# requestsì™€ gradio APIë¥¼ Importí•¨\n",
    "import requests  \n",
    "import gradio as gr\n",
    "\n",
    "# open AI request ë°›ì•„ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def request_gpt(prompt, histories=[]):\n",
    "    ai_search_endpoint = \"https://team9-ai-search.search.windows.net/\"\n",
    "    ai_search_key = \"xVtlSUATNV7DwdHB4JOdzhLvYyEZz4LdUFgKXyWzJiAzSeAvOyxo\"\n",
    "    ai_search_index = \"jeju-dialect-index-delete\"\n",
    "    endpoint = \"https://team9-openai-ncus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview\"\n",
    "    headers = {\n",
    "        \"Content-type\": \"application/json\",\n",
    "        \"api-key\": \"7U7x0fAWIHKby0AXBpGGr3zjI52iTr9xb7pFKmCH7eBnrdytwXrCJQQJ99BAACHrzpqXJ3w3AAABACOGuqAv\"\n",
    "    }\n",
    "    \n",
    "    message_list = list()\n",
    "    \n",
    "    # ì‹œìŠ¤í…œ ë©”ì‹œì§€, í”„ë¡¬í”„íŠ¸ ì…ë ¥\n",
    "    message_list.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"ë‹¤ìŒì€ ì œì£¼ë„ ë°©ì–¸ì„ í‘œì¤€ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ê³ , í•´ë‹¹ ë°©ì–¸ì˜ ë‹¨ì–´ê°€ ê°€ì§„ ë‹¤ì–‘í•œ ì˜ë¯¸ë¥¼ ë¬¸ë§¥ì— ë”°ë¼ ë¶„ì„í•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤. ë²ˆì—­ëœ ë‚´ìš©ì— ëŒ€í•´ ì°¸ì¡°í•œ ë¬¸ì„œë„ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤. ì¶œë ¥ í˜•ì‹ì€ ì•„ë˜ë¥¼ ë”°ë¦…ë‹ˆë‹¤.\n",
    " \n",
    "# ì¶œë ¥ í˜•ì‹\n",
    "1. **ë‹¨ì–´ ë° ë¬¸ì¥ ë¶„ì„**: ì£¼ì–´ì§„ ë°©ì–¸ ë¬¸ì¥ì— í¬í•¨ëœ ë‹¨ì–´ê°€ ê°€ì§„ ë‹¤ì–‘í•œ ì˜ë¯¸ë¥¼ ë‚˜ì—´í•©ë‹ˆë‹¤. ë¬¸ë§¥ì— ë”°ë¼ ì í•©í•œ ì˜ë¯¸ë¥¼ ì œê³µí•˜ë©°, ìƒí™©ë³„ë¡œ í•´ì„í•  ìˆ˜ ìˆëŠ” ê²½ìš° ì´ë¥¼ ëª…í™•íˆ í‘œê¸°í•©ë‹ˆë‹¤.\n",
    "2. **ì°¸ì¡°**: ë¬¸ì„œë‚˜ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•œ ë‚´ìš©ì„ í‘œì‹œí•©ë‹ˆë‹¤. í•´ë‹¹ ì°¸ì¡°ëŠ” ë²ˆí˜¸ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤.\n",
    " \n",
    "# ì˜ˆì œ ì¶œë ¥\n",
    "ì…ë ¥: \"í˜¼ì € ì˜µì„œì˜ˆ\"\n",
    " \n",
    "ì¶œë ¥:\n",
    "---\n",
    "\"í˜¼ì € ì˜µì„œì˜ˆ\"ë¼ëŠ” ë¬¸ì¥ì—ì„œ ë°©ì–¸ ë‹¨ì–´ë“¤ì´ ê°€ì§„ ë‹¤ì–‘í•œ ì˜ë¯¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "1. í˜¼ì €:\n",
    "   - ë¨¼ì €\n",
    "   - ì–´ì„œ\n",
    "2. ì˜µì„œì˜ˆ:\n",
    "   - ì˜¤ì„¸ìš”\n",
    "   - ë°©ë¬¸í•´ ì£¼ì‹­ì‹œì˜¤\n",
    " \n",
    "ë¬¸ë§¥ì— ë”°ë¼ 'í˜¼ì €'ëŠ” \"ë¨¼ì €\" ë˜ëŠ” \"ì–´ì„œ\"ë¡œ í•´ì„ë  ìˆ˜ ìˆìœ¼ë©°, 'ì˜µì„œì˜ˆ'ëŠ” \"ì˜¤ì„¸ìš”\"ë¡œ ë²ˆì—­ë©ë‹ˆë‹¤.\n",
    "\n",
    " \n",
    "# ì§€ì¹¨\n",
    "- ëª¨ë“  ë‹¨ì–´ë¥¼ ê°€ëŠ¥í•œ í•œ ìì„¸íˆ ë¶„ì„í•©ë‹ˆë‹¤.\n",
    "- ì°¸ì¡°ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰í•œ ê²°ê³¼ì— ê¸°ë°˜í•˜ì—¬ ë²ˆí˜¸ì™€ í•¨ê»˜ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "- ë°©ì–¸ í•´ì„ì´ ëª¨í˜¸í•˜ê±°ë‚˜ ë‹¤ì˜ì ì¸ ê²½ìš°, ê°€ëŠ¥í•œ ëª¨ë“  ì˜ë¯¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "- ë‹¨ì–´ ë° ë¬¸ì¥ì˜ ìµœì¢… í•´ì„ì„ ì‚¬ìš©ìì—ê²Œ ëª…í™•íˆ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "- ì°¸ì¡°ëŠ” ê²°ê³¼ í•˜ë‹¨ì— ë³„ë„ ì„¹ì…˜ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤.\n",
    " \n",
    "ì…ë ¥:\n",
    "\"{ë°©ì–¸ ë¬¸ì¥}\"\n",
    "\n",
    "\n",
    "ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì œì£¼ë„ ë°©ì–¸ ë¬¸ì¥ì„ í‘œì¤€ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤. ì£¼ì–´ì§„ ë°ì´í„°ì— í¬í•¨ëœ ë°©ì–¸ ë‹¨ì–´ë¥¼ ì°¸ì¡°í•˜ì—¬ í‘œì¤€ì–´ ë¬¸ì¥ì„ ë°˜í™˜í•˜ì„¸ìš”.\n",
    " \n",
    "ì˜ˆì‹œ:\n",
    "ì…ë ¥: 'ëˆ„ê²Œ ìˆìˆ˜ê³¼' \n",
    "ì¶œë ¥: 'ëˆ„ê°€ ìˆìŠµë‹ˆê¹Œ?'\n",
    " \n",
    "ì…ë ¥: 'ê²… í•˜ë‹ˆê¹Œì´'\n",
    "ì¶œë ¥:  'ê·¸ëŸ¬ë‹ˆê¹Œ'\n",
    "ì…ë ¥: 'ì˜ˆì´ˆí•˜ë‹¤ê°€ì´ ë±€ ë‚˜ì˜¨ê±°ì•¼' \n",
    "ì¶œë ¥: 'ì˜ˆì´ˆí•˜ë‹¤ê°€ ë±€ì´ ë‚˜ì˜¨ ê±°ì•¼'\n",
    "ì œì¶œëœ ë¬¸ì¥ì—ì„œ ì œì£¼ë„ ë°©ì–¸ ë‹¨ì–´ë¥¼ ì°¾ì•„ ì£¼ì–´ì§„ ë°ì´í„°ì™€ ëŒ€ì¡°í•œ í›„, ê°€ì¥ ì ì ˆí•œ í‘œì¤€ì–´ ë²ˆì—­ì„ ì œê³µí•˜ì„¸ìš”.\n",
    "\"\"\"       \n",
    "        \n",
    "    })\n",
    "\n",
    "    # ì´ì „ ë©”ì‹œì§€ í¬í•¨.\n",
    "    for history in histories:\n",
    "        for text in history:\n",
    "            message_list.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": text\n",
    "                \n",
    "            })\n",
    "\n",
    "    # ìœ ì € ë©”ì‹œì§€.\n",
    "    message_list.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    })            \n",
    "    \n",
    "    payload = {\n",
    "        \"messages\": message_list,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 800,\n",
    "        \"data_sources\": [\n",
    "        {\n",
    "            \"type\": \"azure_search\",\n",
    "            \"parameters\": {\n",
    "                \"endpoint\": ai_search_endpoint,\n",
    "                \"semantic_configuration\": \"jeju-dialect-sementic-delete\",\n",
    "                \"query_type\": \"semantic\",\n",
    "                \"queryLanguage\": \"ko-kr\",\n",
    "                \"strictness\": 2,\n",
    "                \"top_n_documents\": 10,\n",
    "                \"key\": ai_search_key,\n",
    "                \"indexName\": ai_search_index\n",
    "            }\n",
    "        }\n",
    "        ],\n",
    "    }  \n",
    "    \n",
    "    # endpointì™€ headers, jsonì— payload requestsí•¨\n",
    "    response = requests.post(endpoint, headers=headers, json=payload)\n",
    "    print(response.status_code)\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        print(response_json)\n",
    "        content = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        citations = response_json[\"choices\"][0][\"message\"].get(\"context\", {}).get(\"citations\", [])\n",
    "        formatted_citation_list = []\n",
    "        \n",
    "        if citations:\n",
    "            for i, citation in enumerate(citations, start=1):\n",
    "                formatted_citation = f\"<details><summary>ì°¸ì¡° {i}</summary><ul>{citation['content']}</ul></details>\"\n",
    "                formatted_citation_list.append(formatted_citation)\n",
    "\n",
    "        return content, \"\".join(formatted_citation_list)\n",
    "    else:\n",
    "        return f\"{response.status_code}, {response.text}\", \"\"\n",
    "\n",
    "#REST APIë¥¼ í†µí•˜ì—¬ STT FAST request\n",
    "def request_stt_fast(file_path):\n",
    "    endpoint = \"https://eastus.api.cognitive.microsoft.com/speechtotext/transcriptions:transcribe?api-version=2024-11-15\"\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": \"EXdCQatIT6OYg5RRAwYr7A6JTvRyDfYzJ8VS6HUMIUpKeB8wcKOqJQQJ99BAACYeBjFXJ3w3AAAYACOGWEOf\",\n",
    "    }\n",
    "\n",
    "    with open(file_path, \"rb\") as audio :\n",
    "        audio_data = audio.read()\n",
    "\n",
    "    json = {\n",
    "        \"definition\": '{\"locales\":[\"ko-KR\"], \"profanityFilterMode\":\"Masked\", \"channels\":[0,1]}'\n",
    "    }\n",
    "\n",
    "    files = {\n",
    "        \"audio\" : audio_data\n",
    "    }\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers,files=files, json=json)\n",
    "\n",
    "    print(\"Fast\", response.status_code, response.elapsed.total_seconds())\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        response_text = response_json['combinedPhrases'][0]['text']\n",
    "        print(response_text)\n",
    "        return response_text\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "#ì „ì†¡ ë²„íŠ¼ì„ ëˆŒë €ì„ ì‹œ í•¨ìˆ˜\n",
    "def click_send(prompt, histories):\n",
    "    #response_textì— gpt ëŒ€ë‹µ, citaion_htmlì— ì£¼ì„ì„ ë°›ìŒ\n",
    "    response_text, citation_html = request_gpt(prompt=prompt, histories=histories)\n",
    "    histories.append((prompt, response_text))\n",
    "    #ë¦¬í„´ ê°’ìœ¼ë¡œ gptëŒ€ë‹µì´ ë“¤ì–´ê°„ histories ë¦¬ìŠ¤íŠ¸ì™€ ì£¼ì„ì´ ë“¤ì–´ê°„ citation_htmlì„ ì¤Œ\n",
    "    return histories, citation_html, \"\"\n",
    "\n",
    "#ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë°”ê¿”ì¤Œì¤Œ\n",
    "def change_audio(file_path):\n",
    "    #ë§Œì•½ file_pathê°€ ìœ íš¨ê°’ ì¦‰ ìŒì„± íŒŒì¼ì´ ìˆìœ¼ë©´\n",
    "    if file_path:\n",
    "        #response_textì— ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì¤Œ\n",
    "        response_text = request_stt_fast(file_path=file_path)\n",
    "        return response_text\n",
    "    else:\n",
    "        #ìŒì„±íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¦¬í„´ê°’ìœ¼ë¡œ ë¹ˆê°’ì„ ì¤Œ\n",
    "        return ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\utility\\Python\\Lib\\site-packages\\gradio\\components\\chatbot.py:282: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    with gr.Tab(label=\"ğŸ—£ï¸ğŸ”„ì œì£¼ë°©ì–¸ ë²ˆì—­\")  as tab2:\n",
    "        gr.Markdown(\"ğŸï¸ì œì£¼ë°©ì–¸ ë²ˆì—­\")\n",
    "\n",
    "        # ìŒì„± ì…ë ¥ ë° ê²°ê³¼ ì¶œë ¥\n",
    "        with gr.Column():\n",
    "            input_mic = gr.Audio(\n",
    "                label=\"ğŸ¤ ë§ˆì´í¬ ì…ë ¥\",\n",
    "                sources=\"microphone\",\n",
    "                type=\"filepath\",\n",
    "                interactive=True, waveform_options=gr.WaveformOptions(\n",
    "                    waveform_color=\"#D3B1C2\",\n",
    "                    waveform_progress_color=\"#C197D@\",\n",
    "                    skip_length=2,\n",
    "                    show_controls=False)\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "        # í”„ë¡¬í”„íŠ¸ ì…ë ¥ê³¼ ê²°ê³¼\n",
    "        gr.Markdown(\"### ğŸ—£ï¸ğŸ”„ ë²ˆì—­ ë‚´ìš©\")\n",
    "        chatbot_gpt = gr.Chatbot(\n",
    "            label=\"ğŸ—£ï¸ğŸ”„ ë²ˆì—­ ë‚´ìš©\", \n",
    "            height=200\n",
    "        )\n",
    "        #ì£¼ì„\n",
    "        citation = gr.HTML(label=\"ğŸ”— ì°¸ì¡° ë§í¬\")\n",
    "\n",
    "\n",
    "        input_openai_textbox = gr.Textbox(\n",
    "                label=\"ğŸ“ í…ìŠ¤íŠ¸\", \n",
    "                interactive=True, \n",
    "            )\n",
    "        send_button = gr.Button(\"ì „ì†¡\")\n",
    "        \n",
    "        input_mic.change(\n",
    "            fn=change_audio, \n",
    "            inputs=[input_mic], \n",
    "            outputs=[input_openai_textbox]\n",
    "        )\n",
    "        send_button.click(\n",
    "            fn=click_send,\n",
    "            inputs=[input_openai_textbox, chatbot_gpt],\n",
    "            outputs=[chatbot_gpt, citation, input_openai_textbox]\n",
    "        )\n",
    "        input_openai_textbox.submit(\n",
    "            fn=click_send,\n",
    "            inputs=[input_openai_textbox, chatbot_gpt],\n",
    "            outputs=[chatbot_gpt, citation, input_openai_textbox]\n",
    "        )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\utility\\Python\\Lib\\site-packages\\gradio\\components\\chatbot.py:282: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "import gradio as gr\n",
    "\n",
    "# open AI request ë°›ì•„ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def request_gpt(prompt, histories=[]):\n",
    "    ai_search_endpoint = \"https://team9-ai-search.search.windows.net/\"\n",
    "    ai_search_key = \"xVtlSUATNV7DwdHB4JOdzhLvYyEZz4LdUFgKXyWzJiAzSeAvOyxo\"\n",
    "    ai_search_index = \"jeju-dialect-index-delete\"\n",
    "    endpoint = \"https://team9-openai-ncus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview\"\n",
    "    headers = {\n",
    "        \"Content-type\": \"application/json\",\n",
    "        \"api-key\": \"7U7x0fAWIHKby0AXBpGGr3zjI52iTr9xb7pFKmCH7eBnrdytwXrCJQQJ99BAACHrzpqXJ3w3AAABACOGuqAv\"\n",
    "    }\n",
    "    \n",
    "    message_list = list()\n",
    "    \n",
    "    # ì‹œìŠ¤í…œ ë©”ì‹œì§€\n",
    "    message_list.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"ë‹¤ìŒì€ ì œì£¼ë„ ë°©ì–¸ì„ í‘œì¤€ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ê³ , í•´ë‹¹ ë°©ì–¸ì˜ ë‹¨ì–´ê°€ ê°€ì§„ ë‹¤ì–‘í•œ ì˜ë¯¸ë¥¼ ë¬¸ë§¥ì— ë”°ë¼ ë¶„ì„í•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤. ë²ˆì—­ëœ ë‚´ìš©ì— ëŒ€í•´ ì°¸ì¡°í•œ ë¬¸ì„œë„ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤. ì¶œë ¥ í˜•ì‹ì€ ì•„ë˜ë¥¼ ë”°ë¦…ë‹ˆë‹¤.\n",
    " \n",
    "# ì¶œë ¥ í˜•ì‹\n",
    "1. **ë‹¨ì–´ ë° ë¬¸ì¥ ë¶„ì„**: ì£¼ì–´ì§„ ë°©ì–¸ ë¬¸ì¥ì— í¬í•¨ëœ ë‹¨ì–´ê°€ ê°€ì§„ ë‹¤ì–‘í•œ ì˜ë¯¸ë¥¼ ë‚˜ì—´í•©ë‹ˆë‹¤. ë¬¸ë§¥ì— ë”°ë¼ ì í•©í•œ ì˜ë¯¸ë¥¼ ì œê³µí•˜ë©°, ìƒí™©ë³„ë¡œ í•´ì„í•  ìˆ˜ ìˆëŠ” ê²½ìš° ì´ë¥¼ ëª…í™•íˆ í‘œê¸°í•©ë‹ˆë‹¤.\n",
    "2. **ì°¸ì¡°**: ë¬¸ì„œë‚˜ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•œ ë‚´ìš©ì„ í‘œì‹œí•©ë‹ˆë‹¤. í•´ë‹¹ ì°¸ì¡°ëŠ” ë²ˆí˜¸ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤.\n",
    " \n",
    "# ì˜ˆì œ ì¶œë ¥\n",
    "ì…ë ¥: \"í˜¼ì € ì˜µì„œì˜ˆ\"\n",
    " \n",
    "ì¶œë ¥:\n",
    "---\n",
    "\"í˜¼ì € ì˜µì„œì˜ˆ\"ë¼ëŠ” ë¬¸ì¥ì—ì„œ ë°©ì–¸ ë‹¨ì–´ë“¤ì´ ê°€ì§„ ë‹¤ì–‘í•œ ì˜ë¯¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "1. í˜¼ì €:\n",
    "   - ë¨¼ì €\n",
    "   - ì–´ì„œ\n",
    "2. ì˜µì„œì˜ˆ:\n",
    "   - ì˜¤ì„¸ìš”\n",
    "   - ë°©ë¬¸í•´ ì£¼ì‹­ì‹œì˜¤\n",
    " \n",
    "ë¬¸ë§¥ì— ë”°ë¼ 'í˜¼ì €'ëŠ” \"ë¨¼ì €\" ë˜ëŠ” \"ì–´ì„œ\"ë¡œ í•´ì„ë  ìˆ˜ ìˆìœ¼ë©°, 'ì˜µì„œì˜ˆ'ëŠ” \"ì˜¤ì„¸ìš”\"ë¡œ ë²ˆì—­ë©ë‹ˆë‹¤.\n",
    "\n",
    " \n",
    "# ì§€ì¹¨\n",
    "- ëª¨ë“  ë‹¨ì–´ë¥¼ ê°€ëŠ¥í•œ í•œ ìì„¸íˆ ë¶„ì„í•©ë‹ˆë‹¤.\n",
    "- ì°¸ì¡°ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰í•œ ê²°ê³¼ì— ê¸°ë°˜í•˜ì—¬ ë²ˆí˜¸ì™€ í•¨ê»˜ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "- ë°©ì–¸ í•´ì„ì´ ëª¨í˜¸í•˜ê±°ë‚˜ ë‹¤ì˜ì ì¸ ê²½ìš°, ê°€ëŠ¥í•œ ëª¨ë“  ì˜ë¯¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "- ë‹¨ì–´ ë° ë¬¸ì¥ì˜ ìµœì¢… í•´ì„ì„ ì‚¬ìš©ìì—ê²Œ ëª…í™•íˆ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "- ì°¸ì¡°ëŠ” ê²°ê³¼ í•˜ë‹¨ì— ë³„ë„ ì„¹ì…˜ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤.\n",
    " \n",
    "ì…ë ¥:\n",
    "\"{ë°©ì–¸ ë¬¸ì¥}\"\n",
    "\n",
    "\n",
    "ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì œì£¼ë„ ë°©ì–¸ ë¬¸ì¥ì„ í‘œì¤€ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤. ì£¼ì–´ì§„ ë°ì´í„°ì— í¬í•¨ëœ ë°©ì–¸ ë‹¨ì–´ë¥¼ ì°¸ì¡°í•˜ì—¬ í‘œì¤€ì–´ ë¬¸ì¥ì„ ë°˜í™˜í•˜ì„¸ìš”.\n",
    " \n",
    "ì˜ˆì‹œ:\n",
    "ì…ë ¥: 'ëˆ„ê²Œ ìˆìˆ˜ê³¼' \n",
    "ì¶œë ¥: 'ëˆ„ê°€ ìˆìŠµë‹ˆê¹Œ?'\n",
    " \n",
    "ì…ë ¥: 'ê²… í•˜ë‹ˆê¹Œì´'\n",
    "ì¶œë ¥:  'ê·¸ëŸ¬ë‹ˆê¹Œ'\n",
    "ì…ë ¥: 'ì˜ˆì´ˆí•˜ë‹¤ê°€ì´ ë±€ ë‚˜ì˜¨ê±°ì•¼' \n",
    "ì¶œë ¥: 'ì˜ˆì´ˆí•˜ë‹¤ê°€ ë±€ì´ ë‚˜ì˜¨ ê±°ì•¼'\n",
    "ì œì¶œëœ ë¬¸ì¥ì—ì„œ ì œì£¼ë„ ë°©ì–¸ ë‹¨ì–´ë¥¼ ì°¾ì•„ ì£¼ì–´ì§„ ë°ì´í„°ì™€ ëŒ€ì¡°í•œ í›„, ê°€ì¥ ì ì ˆí•œ í‘œì¤€ì–´ ë²ˆì—­ì„ ì œê³µí•˜ì„¸ìš”.\n",
    "\"\"\"       \n",
    "        \n",
    "    })\n",
    "\n",
    "    # ì´ì „ ë©”ì‹œì§€ í¬í•¨.\n",
    "    for history in histories:\n",
    "        for text in history:\n",
    "            message_list.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": text\n",
    "                \n",
    "            })\n",
    "\n",
    "    # ìœ ì € ë©”ì‹œì§€.\n",
    "    message_list.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    })            \n",
    "    \n",
    "    payload = {\n",
    "        \"messages\": message_list,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 800,\n",
    "        \"data_sources\": [\n",
    "        {\n",
    "            \"type\": \"azure_search\",\n",
    "            \"parameters\": {\n",
    "                \"endpoint\": ai_search_endpoint,\n",
    "                \"semantic_configuration\": \"jeju-dialect-sementic-delete\",\n",
    "                \"query_type\": \"semantic\",\n",
    "                \"queryLanguage\": \"ko-kr\",\n",
    "                \"strictness\": 2,\n",
    "                \"top_n_documents\": 10,\n",
    "                \"key\": ai_search_key,\n",
    "                \"indexName\": ai_search_index\n",
    "            }\n",
    "        }\n",
    "        ],\n",
    "    }  \n",
    "    \n",
    "    response = requests.post(endpoint, headers=headers, json=payload)\n",
    "    print(response.status_code)\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        print(response_json)\n",
    "        content = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        citations = response_json[\"choices\"][0][\"message\"].get(\"context\", {}).get(\"citations\", [])\n",
    "        formatted_citation_list = []\n",
    "        \n",
    "        if citations:\n",
    "            for i, citation in enumerate(citations, start=1):\n",
    "                formatted_citation = f\"<details><summary>ì°¸ì¡° {i}</summary><ul>{citation['content']}</ul></details>\"\n",
    "                formatted_citation_list.append(formatted_citation)\n",
    "\n",
    "        return content, \"\".join(formatted_citation_list)\n",
    "    else:\n",
    "        return f\"{response.status_code}, {response.text}\", \"\"\n",
    "\n",
    "def request_stt_fast(file_path):\n",
    "    endpoint = \"https://eastus.api.cognitive.microsoft.com/speechtotext/transcriptions:transcribe?api-version=2024-11-15\"\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": \"EXdCQatIT6OYg5RRAwYr7A6JTvRyDfYzJ8VS6HUMIUpKeB8wcKOqJQQJ99BAACYeBjFXJ3w3AAAYACOGWEOf\",\n",
    "    }\n",
    "\n",
    "    with open(file_path, \"rb\") as audio :\n",
    "        audio_data = audio.read()\n",
    "\n",
    "    json = {\n",
    "        \"definition\": '{\"locales\":[\"ko-KR\"], \"profanityFilterMode\":\"Masked\", \"channels\":[0,1]}'\n",
    "    }\n",
    "\n",
    "    files = {\n",
    "        \"audio\" : audio_data\n",
    "    }\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers,files=files, json=json)\n",
    "\n",
    "    print(\"Fast\", response.status_code, response.elapsed.total_seconds())\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        response_text = response_json['combinedPhrases'][0]['text']\n",
    "        print(response_text)\n",
    "        return response_text\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def click_send(prompt, histories):\n",
    "    response_text, citation_html = request_gpt(prompt=prompt, histories=histories)\n",
    "    histories.append((prompt, response_text))\n",
    "    return histories, citation_html, \"\"\n",
    "\n",
    "def change_audio(file_path):\n",
    "    if file_path:\n",
    "        response_text = request_stt_fast(file_path=file_path)\n",
    "        return response_text\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    with gr.Tab(label=\"ğŸ—£ï¸ğŸ”„ì œì£¼ë°©ì–¸ ë²ˆì—­\")  as tab2:\n",
    "        gr.Markdown(\"ğŸï¸ì œì£¼ë°©ì–¸ ë²ˆì—­\")\n",
    "\n",
    "        # ìŒì„± ì…ë ¥ ë° ê²°ê³¼ ì¶œë ¥\n",
    "        with gr.Column():\n",
    "            input_mic = gr.Audio(\n",
    "                label=\"ğŸ¤ ë§ˆì´í¬ ì…ë ¥\",\n",
    "                sources=\"microphone\",\n",
    "                type=\"filepath\",\n",
    "                interactive=True, waveform_options=gr.WaveformOptions(\n",
    "                    waveform_color=\"#D3B1C2\",\n",
    "                    waveform_progress_color=\"#C197D@\",\n",
    "                    skip_length=2,\n",
    "                    show_controls=False)\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "        # í”„ë¡¬í”„íŠ¸ ì…ë ¥ê³¼ ê²°ê³¼\n",
    "        gr.Markdown(\"### ğŸ—£ï¸ğŸ”„ ë²ˆì—­ ë‚´ìš©\")\n",
    "        chatbot_gpt = gr.Chatbot(\n",
    "            label=\"ğŸ—£ï¸ğŸ”„ ë²ˆì—­ ë‚´ìš©\", \n",
    "            height=200\n",
    "        )\n",
    "        citation = gr.HTML(label=\"ğŸ”— ì°¸ì¡° ë§í¬\")\n",
    "\n",
    "        input_openai_textbox = gr.Textbox(\n",
    "                label=\"ğŸ“ í…ìŠ¤íŠ¸\", \n",
    "                interactive=True, \n",
    "            )\n",
    "        send_button = gr.Button(\"ì „ì†¡\")\n",
    "        \n",
    "        input_mic.change(\n",
    "            fn=change_audio, \n",
    "            inputs=[input_mic], \n",
    "            outputs=[input_openai_textbox]\n",
    "        )\n",
    "        send_button.click(\n",
    "            fn=click_send,\n",
    "            inputs=[input_openai_textbox, chatbot_gpt],\n",
    "            outputs=[chatbot_gpt, citation, input_openai_textbox]\n",
    "        )\n",
    "        input_openai_textbox.submit(\n",
    "            fn=click_send,\n",
    "            inputs=[input_openai_textbox, chatbot_gpt],\n",
    "            outputs=[chatbot_gpt, citation, input_openai_textbox]\n",
    "        )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
