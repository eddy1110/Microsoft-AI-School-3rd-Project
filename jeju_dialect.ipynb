{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\utility\\Python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# requests와 gradio API를 Import함\n",
    "import requests  \n",
    "import gradio as gr\n",
    "\n",
    "# open AI request 받아오는 함수\n",
    "def request_gpt(prompt, histories=[]):\n",
    "    ai_search_endpoint = \"https://team9-ai-search.search.windows.net/\"\n",
    "    ai_search_key = \"xVtlSUATNV7DwdHB4JOdzhLvYyEZz4LdUFgKXyWzJiAzSeAvOyxo\"\n",
    "    ai_search_index = \"jeju-dialect-index-delete\"\n",
    "    endpoint = \"https://team9-openai-ncus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview\"\n",
    "    headers = {\n",
    "        \"Content-type\": \"application/json\",\n",
    "        \"api-key\": \"7U7x0fAWIHKby0AXBpGGr3zjI52iTr9xb7pFKmCH7eBnrdytwXrCJQQJ99BAACHrzpqXJ3w3AAABACOGuqAv\"\n",
    "    }\n",
    "    \n",
    "    message_list = list()\n",
    "    \n",
    "    # 시스템 메시지, 프롬프트 입력\n",
    "    message_list.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"다음은 제주도 방언을 표준 한국어로 번역하고, 해당 방언의 단어가 가진 다양한 의미를 문맥에 따라 분석하는 역할입니다. 번역된 내용에 대해 참조한 문서도 함께 제공합니다. 출력 형식은 아래를 따릅니다.\n",
    " \n",
    "# 출력 형식\n",
    "1. **단어 및 문장 분석**: 주어진 방언 문장에 포함된 단어가 가진 다양한 의미를 나열합니다. 문맥에 따라 적합한 의미를 제공하며, 상황별로 해석할 수 있는 경우 이를 명확히 표기합니다.\n",
    "2. **참조**: 문서나 데이터베이스를 기반으로 분석한 내용을 표시합니다. 해당 참조는 번호로 구분됩니다.\n",
    " \n",
    "# 예제 출력\n",
    "입력: \"혼저 옵서예\"\n",
    " \n",
    "출력:\n",
    "---\n",
    "\"혼저 옵서예\"라는 문장에서 방언 단어들이 가진 다양한 의미는 다음과 같습니다:\n",
    "1. 혼저:\n",
    "   - 먼저\n",
    "   - 어서\n",
    "2. 옵서예:\n",
    "   - 오세요\n",
    "   - 방문해 주십시오\n",
    " \n",
    "문맥에 따라 '혼저'는 \"먼저\" 또는 \"어서\"로 해석될 수 있으며, '옵서예'는 \"오세요\"로 번역됩니다.\n",
    "\n",
    " \n",
    "# 지침\n",
    "- 모든 단어를 가능한 한 자세히 분석합니다.\n",
    "- 참조는 데이터베이스에서 검색한 결과에 기반하여 번호와 함께 출력합니다.\n",
    "- 방언 해석이 모호하거나 다의적인 경우, 가능한 모든 의미를 제공합니다.\n",
    "- 단어 및 문장의 최종 해석을 사용자에게 명확히 전달합니다.\n",
    "- 참조는 결과 하단에 별도 섹션으로 제공합니다.\n",
    " \n",
    "입력:\n",
    "\"{방언 문장}\"\n",
    "\n",
    "\n",
    "사용자가 입력한 제주도 방언 문장을 표준어로 번역합니다. 주어진 데이터에 포함된 방언 단어를 참조하여 표준어 문장을 반환하세요.\n",
    " \n",
    "예시:\n",
    "입력: '누게 있수과' \n",
    "출력: '누가 있습니까?'\n",
    " \n",
    "입력: '겅 하니까이'\n",
    "출력:  '그러니까'\n",
    "입력: '예초하다가이 뱀 나온거야' \n",
    "출력: '예초하다가 뱀이 나온 거야'\n",
    "제출된 문장에서 제주도 방언 단어를 찾아 주어진 데이터와 대조한 후, 가장 적절한 표준어 번역을 제공하세요.\n",
    "\"\"\"       \n",
    "        \n",
    "    })\n",
    "\n",
    "    # 이전 메시지 포함.\n",
    "    for history in histories:\n",
    "        for text in history:\n",
    "            message_list.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": text\n",
    "                \n",
    "            })\n",
    "\n",
    "    # 유저 메시지.\n",
    "    message_list.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    })            \n",
    "    \n",
    "    payload = {\n",
    "        \"messages\": message_list,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 800,\n",
    "        \"data_sources\": [\n",
    "        {\n",
    "            \"type\": \"azure_search\",\n",
    "            \"parameters\": {\n",
    "                \"endpoint\": ai_search_endpoint,\n",
    "                \"semantic_configuration\": \"jeju-dialect-sementic-delete\",\n",
    "                \"query_type\": \"semantic\",\n",
    "                \"queryLanguage\": \"ko-kr\",\n",
    "                \"strictness\": 2,\n",
    "                \"top_n_documents\": 10,\n",
    "                \"key\": ai_search_key,\n",
    "                \"indexName\": ai_search_index\n",
    "            }\n",
    "        }\n",
    "        ],\n",
    "    }  \n",
    "    \n",
    "    # endpoint와 headers, json에 payload requests함\n",
    "    response = requests.post(endpoint, headers=headers, json=payload)\n",
    "    print(response.status_code)\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        print(response_json)\n",
    "        content = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        citations = response_json[\"choices\"][0][\"message\"].get(\"context\", {}).get(\"citations\", [])\n",
    "        formatted_citation_list = []\n",
    "        \n",
    "        if citations:\n",
    "            for i, citation in enumerate(citations, start=1):\n",
    "                formatted_citation = f\"<details><summary>참조 {i}</summary><ul>{citation['content']}</ul></details>\"\n",
    "                formatted_citation_list.append(formatted_citation)\n",
    "\n",
    "        return content, \"\".join(formatted_citation_list)\n",
    "    else:\n",
    "        return f\"{response.status_code}, {response.text}\", \"\"\n",
    "\n",
    "#REST API를 통하여 STT FAST request\n",
    "def request_stt_fast(file_path):\n",
    "    endpoint = \"https://eastus.api.cognitive.microsoft.com/speechtotext/transcriptions:transcribe?api-version=2024-11-15\"\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": \"EXdCQatIT6OYg5RRAwYr7A6JTvRyDfYzJ8VS6HUMIUpKeB8wcKOqJQQJ99BAACYeBjFXJ3w3AAAYACOGWEOf\",\n",
    "    }\n",
    "\n",
    "    with open(file_path, \"rb\") as audio :\n",
    "        audio_data = audio.read()\n",
    "\n",
    "    json = {\n",
    "        \"definition\": '{\"locales\":[\"ko-KR\"], \"profanityFilterMode\":\"Masked\", \"channels\":[0,1]}'\n",
    "    }\n",
    "\n",
    "    files = {\n",
    "        \"audio\" : audio_data\n",
    "    }\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers,files=files, json=json)\n",
    "\n",
    "    print(\"Fast\", response.status_code, response.elapsed.total_seconds())\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        response_text = response_json['combinedPhrases'][0]['text']\n",
    "        print(response_text)\n",
    "        return response_text\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "#전송 버튼을 눌렀을 시 함수\n",
    "def click_send(prompt, histories):\n",
    "    #response_text에 gpt 대답, citaion_html에 주석을 받음\n",
    "    response_text, citation_html = request_gpt(prompt=prompt, histories=histories)\n",
    "    histories.append((prompt, response_text))\n",
    "    #리턴 값으로 gpt대답이 들어간 histories 리스트와 주석이 들어간 citation_html을 줌\n",
    "    return histories, citation_html, \"\"\n",
    "\n",
    "#오디오를 텍스트로 바꿔줌줌\n",
    "def change_audio(file_path):\n",
    "    #만약 file_path가 유효값 즉 음성 파일이 있으면\n",
    "    if file_path:\n",
    "        #response_text에 음성을 텍스트로 변환해줌\n",
    "        response_text = request_stt_fast(file_path=file_path)\n",
    "        return response_text\n",
    "    else:\n",
    "        #음성파일이 없으면 리턴값으로 빈값을 줌\n",
    "        return ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\utility\\Python\\Lib\\site-packages\\gradio\\components\\chatbot.py:282: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    with gr.Tab(label=\"🗣️🔄제주방언 번역\")  as tab2:\n",
    "        gr.Markdown(\"🏝️제주방언 번역\")\n",
    "\n",
    "        # 음성 입력 및 결과 출력\n",
    "        with gr.Column():\n",
    "            input_mic = gr.Audio(\n",
    "                label=\"🎤 마이크 입력\",\n",
    "                sources=\"microphone\",\n",
    "                type=\"filepath\",\n",
    "                interactive=True, waveform_options=gr.WaveformOptions(\n",
    "                    waveform_color=\"#D3B1C2\",\n",
    "                    waveform_progress_color=\"#C197D@\",\n",
    "                    skip_length=2,\n",
    "                    show_controls=False)\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "        # 프롬프트 입력과 결과\n",
    "        gr.Markdown(\"### 🗣️🔄 번역 내용\")\n",
    "        chatbot_gpt = gr.Chatbot(\n",
    "            label=\"🗣️🔄 번역 내용\", \n",
    "            height=200\n",
    "        )\n",
    "        #주석\n",
    "        citation = gr.HTML(label=\"🔗 참조 링크\")\n",
    "\n",
    "\n",
    "        input_openai_textbox = gr.Textbox(\n",
    "                label=\"📝 텍스트\", \n",
    "                interactive=True, \n",
    "            )\n",
    "        send_button = gr.Button(\"전송\")\n",
    "        \n",
    "        input_mic.change(\n",
    "            fn=change_audio, \n",
    "            inputs=[input_mic], \n",
    "            outputs=[input_openai_textbox]\n",
    "        )\n",
    "        send_button.click(\n",
    "            fn=click_send,\n",
    "            inputs=[input_openai_textbox, chatbot_gpt],\n",
    "            outputs=[chatbot_gpt, citation, input_openai_textbox]\n",
    "        )\n",
    "        input_openai_textbox.submit(\n",
    "            fn=click_send,\n",
    "            inputs=[input_openai_textbox, chatbot_gpt],\n",
    "            outputs=[chatbot_gpt, citation, input_openai_textbox]\n",
    "        )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\utility\\Python\\Lib\\site-packages\\gradio\\components\\chatbot.py:282: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "import gradio as gr\n",
    "\n",
    "# open AI request 받아오는 함수\n",
    "def request_gpt(prompt, histories=[]):\n",
    "    ai_search_endpoint = \"https://team9-ai-search.search.windows.net/\"\n",
    "    ai_search_key = \"xVtlSUATNV7DwdHB4JOdzhLvYyEZz4LdUFgKXyWzJiAzSeAvOyxo\"\n",
    "    ai_search_index = \"jeju-dialect-index-delete\"\n",
    "    endpoint = \"https://team9-openai-ncus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview\"\n",
    "    headers = {\n",
    "        \"Content-type\": \"application/json\",\n",
    "        \"api-key\": \"7U7x0fAWIHKby0AXBpGGr3zjI52iTr9xb7pFKmCH7eBnrdytwXrCJQQJ99BAACHrzpqXJ3w3AAABACOGuqAv\"\n",
    "    }\n",
    "    \n",
    "    message_list = list()\n",
    "    \n",
    "    # 시스템 메시지\n",
    "    message_list.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"다음은 제주도 방언을 표준 한국어로 번역하고, 해당 방언의 단어가 가진 다양한 의미를 문맥에 따라 분석하는 역할입니다. 번역된 내용에 대해 참조한 문서도 함께 제공합니다. 출력 형식은 아래를 따릅니다.\n",
    " \n",
    "# 출력 형식\n",
    "1. **단어 및 문장 분석**: 주어진 방언 문장에 포함된 단어가 가진 다양한 의미를 나열합니다. 문맥에 따라 적합한 의미를 제공하며, 상황별로 해석할 수 있는 경우 이를 명확히 표기합니다.\n",
    "2. **참조**: 문서나 데이터베이스를 기반으로 분석한 내용을 표시합니다. 해당 참조는 번호로 구분됩니다.\n",
    " \n",
    "# 예제 출력\n",
    "입력: \"혼저 옵서예\"\n",
    " \n",
    "출력:\n",
    "---\n",
    "\"혼저 옵서예\"라는 문장에서 방언 단어들이 가진 다양한 의미는 다음과 같습니다:\n",
    "1. 혼저:\n",
    "   - 먼저\n",
    "   - 어서\n",
    "2. 옵서예:\n",
    "   - 오세요\n",
    "   - 방문해 주십시오\n",
    " \n",
    "문맥에 따라 '혼저'는 \"먼저\" 또는 \"어서\"로 해석될 수 있으며, '옵서예'는 \"오세요\"로 번역됩니다.\n",
    "\n",
    " \n",
    "# 지침\n",
    "- 모든 단어를 가능한 한 자세히 분석합니다.\n",
    "- 참조는 데이터베이스에서 검색한 결과에 기반하여 번호와 함께 출력합니다.\n",
    "- 방언 해석이 모호하거나 다의적인 경우, 가능한 모든 의미를 제공합니다.\n",
    "- 단어 및 문장의 최종 해석을 사용자에게 명확히 전달합니다.\n",
    "- 참조는 결과 하단에 별도 섹션으로 제공합니다.\n",
    " \n",
    "입력:\n",
    "\"{방언 문장}\"\n",
    "\n",
    "\n",
    "사용자가 입력한 제주도 방언 문장을 표준어로 번역합니다. 주어진 데이터에 포함된 방언 단어를 참조하여 표준어 문장을 반환하세요.\n",
    " \n",
    "예시:\n",
    "입력: '누게 있수과' \n",
    "출력: '누가 있습니까?'\n",
    " \n",
    "입력: '겅 하니까이'\n",
    "출력:  '그러니까'\n",
    "입력: '예초하다가이 뱀 나온거야' \n",
    "출력: '예초하다가 뱀이 나온 거야'\n",
    "제출된 문장에서 제주도 방언 단어를 찾아 주어진 데이터와 대조한 후, 가장 적절한 표준어 번역을 제공하세요.\n",
    "\"\"\"       \n",
    "        \n",
    "    })\n",
    "\n",
    "    # 이전 메시지 포함.\n",
    "    for history in histories:\n",
    "        for text in history:\n",
    "            message_list.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": text\n",
    "                \n",
    "            })\n",
    "\n",
    "    # 유저 메시지.\n",
    "    message_list.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    })            \n",
    "    \n",
    "    payload = {\n",
    "        \"messages\": message_list,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 800,\n",
    "        \"data_sources\": [\n",
    "        {\n",
    "            \"type\": \"azure_search\",\n",
    "            \"parameters\": {\n",
    "                \"endpoint\": ai_search_endpoint,\n",
    "                \"semantic_configuration\": \"jeju-dialect-sementic-delete\",\n",
    "                \"query_type\": \"semantic\",\n",
    "                \"queryLanguage\": \"ko-kr\",\n",
    "                \"strictness\": 2,\n",
    "                \"top_n_documents\": 10,\n",
    "                \"key\": ai_search_key,\n",
    "                \"indexName\": ai_search_index\n",
    "            }\n",
    "        }\n",
    "        ],\n",
    "    }  \n",
    "    \n",
    "    response = requests.post(endpoint, headers=headers, json=payload)\n",
    "    print(response.status_code)\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        print(response_json)\n",
    "        content = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        citations = response_json[\"choices\"][0][\"message\"].get(\"context\", {}).get(\"citations\", [])\n",
    "        formatted_citation_list = []\n",
    "        \n",
    "        if citations:\n",
    "            for i, citation in enumerate(citations, start=1):\n",
    "                formatted_citation = f\"<details><summary>참조 {i}</summary><ul>{citation['content']}</ul></details>\"\n",
    "                formatted_citation_list.append(formatted_citation)\n",
    "\n",
    "        return content, \"\".join(formatted_citation_list)\n",
    "    else:\n",
    "        return f\"{response.status_code}, {response.text}\", \"\"\n",
    "\n",
    "def request_stt_fast(file_path):\n",
    "    endpoint = \"https://eastus.api.cognitive.microsoft.com/speechtotext/transcriptions:transcribe?api-version=2024-11-15\"\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": \"EXdCQatIT6OYg5RRAwYr7A6JTvRyDfYzJ8VS6HUMIUpKeB8wcKOqJQQJ99BAACYeBjFXJ3w3AAAYACOGWEOf\",\n",
    "    }\n",
    "\n",
    "    with open(file_path, \"rb\") as audio :\n",
    "        audio_data = audio.read()\n",
    "\n",
    "    json = {\n",
    "        \"definition\": '{\"locales\":[\"ko-KR\"], \"profanityFilterMode\":\"Masked\", \"channels\":[0,1]}'\n",
    "    }\n",
    "\n",
    "    files = {\n",
    "        \"audio\" : audio_data\n",
    "    }\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers,files=files, json=json)\n",
    "\n",
    "    print(\"Fast\", response.status_code, response.elapsed.total_seconds())\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        response_text = response_json['combinedPhrases'][0]['text']\n",
    "        print(response_text)\n",
    "        return response_text\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def click_send(prompt, histories):\n",
    "    response_text, citation_html = request_gpt(prompt=prompt, histories=histories)\n",
    "    histories.append((prompt, response_text))\n",
    "    return histories, citation_html, \"\"\n",
    "\n",
    "def change_audio(file_path):\n",
    "    if file_path:\n",
    "        response_text = request_stt_fast(file_path=file_path)\n",
    "        return response_text\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    with gr.Tab(label=\"🗣️🔄제주방언 번역\")  as tab2:\n",
    "        gr.Markdown(\"🏝️제주방언 번역\")\n",
    "\n",
    "        # 음성 입력 및 결과 출력\n",
    "        with gr.Column():\n",
    "            input_mic = gr.Audio(\n",
    "                label=\"🎤 마이크 입력\",\n",
    "                sources=\"microphone\",\n",
    "                type=\"filepath\",\n",
    "                interactive=True, waveform_options=gr.WaveformOptions(\n",
    "                    waveform_color=\"#D3B1C2\",\n",
    "                    waveform_progress_color=\"#C197D@\",\n",
    "                    skip_length=2,\n",
    "                    show_controls=False)\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "        # 프롬프트 입력과 결과\n",
    "        gr.Markdown(\"### 🗣️🔄 번역 내용\")\n",
    "        chatbot_gpt = gr.Chatbot(\n",
    "            label=\"🗣️🔄 번역 내용\", \n",
    "            height=200\n",
    "        )\n",
    "        citation = gr.HTML(label=\"🔗 참조 링크\")\n",
    "\n",
    "        input_openai_textbox = gr.Textbox(\n",
    "                label=\"📝 텍스트\", \n",
    "                interactive=True, \n",
    "            )\n",
    "        send_button = gr.Button(\"전송\")\n",
    "        \n",
    "        input_mic.change(\n",
    "            fn=change_audio, \n",
    "            inputs=[input_mic], \n",
    "            outputs=[input_openai_textbox]\n",
    "        )\n",
    "        send_button.click(\n",
    "            fn=click_send,\n",
    "            inputs=[input_openai_textbox, chatbot_gpt],\n",
    "            outputs=[chatbot_gpt, citation, input_openai_textbox]\n",
    "        )\n",
    "        input_openai_textbox.submit(\n",
    "            fn=click_send,\n",
    "            inputs=[input_openai_textbox, chatbot_gpt],\n",
    "            outputs=[chatbot_gpt, citation, input_openai_textbox]\n",
    "        )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
